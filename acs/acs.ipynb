{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import regex as re\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open elections.xlsx\n",
    "elections = pd.read_excel('elections.xlsx')\n",
    "# open elections_with_geocodes.xlsx\n",
    "geocodes = pd.read_excel('elections_with_geocodes.xlsx')\n",
    "# open elections_with_tracts.xlsx\n",
    "tracts = pd.read_excel('elections_with_tracts.xlsx')\n",
    "\n",
    "groups = ['DP02', 'DP03', 'DP05']\n",
    "key = 'ad8851f3bf6aaf76923ec4119b6f714cdfaa87d9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_dict = {'state': [], 'county': [], 'tract': [], 'year': []}\n",
    "\n",
    "# for each row in elections\n",
    "for index, row in elections.iterrows():\n",
    "    # if District # is not nan\n",
    "    if not pd.isna(row['District #']):\n",
    "        # get row in tracts where filename is the same\n",
    "        tract_row = tracts[tracts['filename'] == row['filename']]\n",
    "        # combine tract_list with tract_row['tracts']\n",
    "        # make sure is not nan\n",
    "        if not pd.isna(tract_row['tracts'].iloc[0]):\n",
    "            new_tracts = tract_row['tracts'].iloc[0].split(',')\n",
    "            # add to tracts_df\n",
    "            for new_tract in new_tracts:\n",
    "                # split new_tract on _\n",
    "                new_tract_split = new_tract.split('_')\n",
    "                # add to tracts_dict\n",
    "                tracts_dict['state'].append(new_tract_split[0])\n",
    "                tracts_dict['county'].append(new_tract_split[1])\n",
    "                tracts_dict['tract'].append(new_tract_split[2])\n",
    "                tracts_dict['year'].append(row['year'])\n",
    "            \n",
    "# create tracts_df\n",
    "tracts_df = pd.DataFrame(tracts_dict)\n",
    "\n",
    "# remove duplicates\n",
    "tracts_df = tracts_df.drop_duplicates()\n",
    "\n",
    "# reset index on tracts_df\n",
    "tracts_df = tracts_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 6476\n",
      "10 of 6476\n",
      "20 of 6476\n",
      "30 of 6476\n",
      "40 of 6476\n",
      "50 of 6476\n",
      "60 of 6476\n",
      "70 of 6476\n",
      "80 of 6476\n",
      "90 of 6476\n",
      "100 of 6476\n",
      "110 of 6476\n",
      "120 of 6476\n",
      "130 of 6476\n",
      "140 of 6476\n",
      "150 of 6476\n",
      "160 of 6476\n",
      "170 of 6476\n",
      "180 of 6476\n",
      "190 of 6476\n",
      "200 of 6476\n",
      "210 of 6476\n",
      "220 of 6476\n",
      "230 of 6476\n",
      "240 of 6476\n",
      "250 of 6476\n",
      "260 of 6476\n",
      "270 of 6476\n",
      "280 of 6476\n",
      "290 of 6476\n",
      "300 of 6476\n",
      "310 of 6476\n",
      "320 of 6476\n",
      "330 of 6476\n",
      "340 of 6476\n",
      "350 of 6476\n",
      "360 of 6476\n",
      "370 of 6476\n",
      "380 of 6476\n",
      "390 of 6476\n",
      "400 of 6476\n",
      "410 of 6476\n",
      "420 of 6476\n",
      "430 of 6476\n",
      "440 of 6476\n",
      "450 of 6476\n",
      "460 of 6476\n",
      "470 of 6476\n",
      "480 of 6476\n",
      "490 of 6476\n",
      "500 of 6476\n",
      "510 of 6476\n",
      "520 of 6476\n",
      "530 of 6476\n",
      "540 of 6476\n",
      "550 of 6476\n",
      "560 of 6476\n",
      "570 of 6476\n",
      "580 of 6476\n",
      "590 of 6476\n",
      "600 of 6476\n",
      "610 of 6476\n",
      "620 of 6476\n",
      "630 of 6476\n",
      "640 of 6476\n",
      "650 of 6476\n",
      "660 of 6476\n",
      "670 of 6476\n",
      "680 of 6476\n",
      "690 of 6476\n",
      "700 of 6476\n",
      "710 of 6476\n",
      "720 of 6476\n",
      "730 of 6476\n",
      "740 of 6476\n",
      "750 of 6476\n"
     ]
    }
   ],
   "source": [
    "# for each row in tracts_df\n",
    "for index, row in tracts_df.iterrows():\n",
    "    if index < len(acs_data):\n",
    "        continue\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        print(f\"{index} of {len(tracts_df)}\")\n",
    "\n",
    "    state = row['state'].zfill(2)\n",
    "    county = row['county'].zfill(3)\n",
    "    tract = row['tract'].zfill(6)\n",
    "    year = row['year']\n",
    "    \n",
    "    data_dict = {'state': state,\n",
    "                 'county': county,\n",
    "                 'tract': tract,\n",
    "                 'year': year}\n",
    "    \n",
    "    if year <= 2005:\n",
    "        adjusted_year = 2009\n",
    "    elif year >= 2021:\n",
    "        adjusted_year = 2022\n",
    "    else:\n",
    "        adjusted_year = year + 2\n",
    "\n",
    "    for query_year in range(adjusted_year, adjusted_year - 3, -1):\n",
    "        try: \n",
    "            for group in groups:\n",
    "                url = f\"https://api.census.gov/data/{query_year}/acs/acs5/profile?get=group({group})&for=tract:{tract}&in=state:{state}+county:{county}&key={key}\"\n",
    "\n",
    "                response = requests.get(url)\n",
    "                data = json.loads(response.text)\n",
    "                # append each array of data to each array of all_data\n",
    "                for i in range(len(data[0])):\n",
    "                    # do the same thing but for E, EA, PE, and PEA\n",
    "                    if re.search(r'\\d(?:E|PE)$', data[0][i]) is not None:\n",
    "                        data_dict[data[0][i]] = data[1][i]\n",
    "            break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if query_year == adjusted_year -3:\n",
    "                print(f\"Error: {e}\")\n",
    "                exit()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    acs_data.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set().union(*(d.keys() for d in acs_data))\n",
    "\n",
    "filled_dicts = [{key: d.get(key) for key in columns} for d in acs_data]\n",
    "\n",
    "df = pd.DataFrame(filled_dicts)\n",
    "\n",
    "# order so that state, county, tract, year are first\n",
    "df = df[['state', 'county', 'tract', 'year'] + [col for col in df.columns if col not in ['state', 'county', 'tract', 'year']]]\n",
    "\n",
    "# save as csv\n",
    "df.to_csv('acs_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
